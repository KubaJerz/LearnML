{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_sf,beds,bath,price,year_built,sqft,price_per_sqft,elevation\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(492, 8)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../sf_vs_nyc_house_data.csv', 'r') as f:\n",
    "    labels = f.readline()\n",
    "\n",
    "print(labels)\n",
    "\n",
    "full_data = np.genfromtxt('../sf_vs_nyc_house_data.csv', delimiter=',')[1:]\n",
    "full_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([112, 134])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample data\n",
    "X = torch.tensor(full_data[::2,1:], dtype=torch.float32)  # 12 samples, each with 7 features\n",
    "\n",
    "X= torch.nn.functional.normalize(X, dim=0)\n",
    "\n",
    "y = torch.squeeze(torch.tensor(full_data[::2,:1], dtype=torch.float32)) # Ensure y is 1-dimensional\n",
    "torch.bincount(y.to(torch.int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class MLP_Large_Adam(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP_Large_Adam, self).__init__()\n",
    "        self.l0 = nn.Linear(7, 1000)  # Increase the number of neurons\n",
    "        self.relu0 = nn.ReLU()\n",
    "        self.l1 = nn.Linear(1000, 800)  # Increase the number of neurons\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.l2 = nn.Linear(800, 600)  # Increase the number of neurons\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.l3 = nn.Linear(600, 400)  # Increase the number of neurons\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.l4 = nn.Linear(400, 200)  # Increase the number of neurons\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.l5 = nn.Linear(200, 100)  # Increase the number of neurons\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.l6 = nn.Linear(100, 50)  # Increase the number of neurons\n",
    "        self.relu6 = nn.ReLU()\n",
    "        self.l7 = nn.Linear(50, 1)\n",
    "        self.out = nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, X):\n",
    "        x = self.l0(X)\n",
    "        x = self.relu0(x)\n",
    "        x = self.l1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.l2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.l3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.l4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.l5(x)\n",
    "        x = self.relu5(x)\n",
    "        x = self.l6(x)\n",
    "        x = self.relu6(x)\n",
    "        x = self.l7(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model\n",
    "model_l_a = MLP_Large_Adam()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(params=model_l_a.parameters(), lr=0.001)  # Adjusted learning rate\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|â–Š         | 845/10000 [00:06<01:08, 133.80it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(output, y)\n\u001b[1;32m      8\u001b[0m     lossi\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m----> 9\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# if (epoch + 1) % 100 == 0:\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m#     print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Evaluation on training data to check overfitting\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "epochs = 10000\n",
    "lossi = []\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    optimizer.zero_grad()\n",
    "    output = model_l_a(X).squeeze()\n",
    "    loss = criterion(output, y)\n",
    "    lossi.append(loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # if (epoch + 1) % 100 == 0:\n",
    "    #     print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluation on training data to check overfitting\n",
    "plt.plot(lossi)\n",
    "\n",
    "model_l_a.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model_l_a(X).squeeze()\n",
    "    predictions = (predictions >= 0.2).float()  # Convert probabilities to binary predictions\n",
    "    accuracy = (predictions == y).float().mean()\n",
    "    print(f'Accuracy on training data: {accuracy:.4f}')\n",
    "\n",
    "cm = confusion_matrix(y.numpy(), predictions.numpy())\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
    "\n",
    "# Plot confusion matrix\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1635201"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model_l_a.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9008304047713236\n"
     ]
    }
   ],
   "source": [
    "print(1635201/ 563701 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
